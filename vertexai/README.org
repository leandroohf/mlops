
* VertexAI + KubeFlow

Simple VertexAI + Kubflow pipeline tutorial. It show 3 stages:

1. preprocessing: generates fake data
2. training: trains 2 models in parallel
3. publishing: upload best model to model artifacts registry

* Set infracstructure

  #+begin_src sh
    PROJECT_ID="mlops-project-abacabb"
    REGION="us-west1" # e.g., us-central1, us-east1, europe-west4
    BUCKET="gs://${PROJECT_ID}-bike-share-project-bucket"

    # NOTE: enable VerexAI service
    gcloud services enable aiplatform.googleapis.com

    # NOTE: make the bucket in the case it does NOT exist
    gsutil mb -l ${REGION} ${BUCKET}

    # NOTE: Setting Docker registry
    gcloud services enable artifactregistry.googleapis.com --project "$PROJECT_ID"

    # create the artifacts registry for docker images if not exists
    export REPO="model-artifacts"
    export LOCATION="us"

    gcloud artifacts repositories create "$REPO" \
           --project "$PROJECT_ID" \
           --repository-format=docker \
           --location="$LOCATION" \
           --description="Training images for Vertex AI"

    # setting docker authentication
    gcloud auth configure-docker "$REGION-docker.pkg.dev"


    # NOTE: build and push image
    # this can be ran by circleci pipelines (not the scope on this project)
    export TAG="vrtx1"
    export IMAGE_URI="$REGION-docker.pkg.dev/$PROJECT_ID/$REPO/$IMAGE:$TAG"
    docker build -t "$IMAGE_URI" .
    docker push "$IMAGE_URI"
  #+end_src



